{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 08:32:13.509395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/panyaang99/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from flax.training import checkpoints\n",
    "# import orbax.checkpoint as ocp \n",
    "import orbax\n",
    "\n",
    "from typing import Any\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import omegaconf\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from model.unetpp import CMPrecond, ScoreDistillPrecond, EDMPrecond\n",
    "from framework.unifying_framework import UnifyingFramework\n",
    "from framework.diffusion.consistency_framework import CMFramework\n",
    "from framework.diffusion.edm_framework import EDMFramework\n",
    "\n",
    "from utils import common_utils\n",
    "from utils.fid_utils import FIDUtils\n",
    "from utils.fs_utils import FSUtils\n",
    "import utils.jax_utils as jax_utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panyaang99/.local/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Setting CM framework for sampling\n",
    "\n",
    "config_path = \"configs\"\n",
    "default_config_path = \"config\"\n",
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "with initialize(version_base=None, config_path=config_path):\n",
    "    default_config = compose(config_name=default_config_path)\n",
    "default_config[\"do_training\"] = False\n",
    "model_type = default_config.type\n",
    "\n",
    "rng, denoiser_rng = jax.random.split(rng, 2)\n",
    "rng, consistency_rng = jax.random.split(rng, 2)\n",
    "# denoiser_framework = diffusion_framework.framework\n",
    "# fid_utils = FIDUtils(default_config)\n",
    "# fs_utils = FSUtils(default_config)\n",
    "\n",
    "# consistency_framework = CMFramework(default_config, consistency_rng, fs_utils, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_framework = default_config.framework.diffusion\n",
    "n_timestep = diffusion_framework['n_timestep']\n",
    "type = diffusion_framework['type']\n",
    "learn_sigma = diffusion_framework['learn_sigma']\n",
    "pmap_axis = \"batch\"\n",
    "\n",
    "# Create UNet and its state\n",
    "model_config = {**default_config.model.diffusion}\n",
    "model_type = model_config.pop(\"type\")\n",
    "\n",
    "head_config = {**default_config.model.head}\n",
    "head_type = head_config.pop(\"type\")\n",
    "head_type = head_type\n",
    "model = CMPrecond(model_config, \n",
    "                        image_channels=model_config['image_channels'], \n",
    "                        model_type=model_type, \n",
    "                        sigma_min=diffusion_framework['sigma_min'],\n",
    "                        sigma_max=diffusion_framework['sigma_max'])\n",
    "head = ScoreDistillPrecond(head_config, \n",
    "                        image_channels=model_config['image_channels'], \n",
    "                        sigma_min=diffusion_framework['sigma_min'],\n",
    "                        sigma_max=diffusion_framework['sigma_max'],\n",
    "                        model_type=head_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TrainState(jax_utils.TrainState):\n",
    "#     target_model: Any = None\n",
    "\n",
    "rng, param_rng, dropout_rng = jax.random.split(rng, 3)\n",
    "rng_dict = {\"params\": param_rng, 'dropout': dropout_rng}\n",
    "input_format = jnp.ones([1, *default_config.dataset.data_size])\n",
    "\n",
    "torso_params = model.init(\n",
    "    rng_dict, x=input_format, sigma=jnp.ones([1,]), train=False, augment_labels=None)['params']\n",
    "\n",
    "D_x, aux = model.apply(\n",
    "        {'params': torso_params}, x=input_format, sigma=jnp.ones([1,]), \n",
    "        train=False, augment_labels=None, rngs={'dropout': dropout_rng})\n",
    "model_tx = jax_utils.create_optimizer(default_config, \"diffusion\")\n",
    "new_torso_state = jax_utils.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=torso_params,\n",
    "    params_ema=torso_params,\n",
    "    # target_model=torso_params, # NEW!\n",
    "    tx=model_tx\n",
    ")\n",
    "torso_state = new_torso_state\n",
    "\n",
    "if False: #not default_config.framework.diffusion.only_cm_training:\n",
    "    F_x, t_emb, last_x_emb = aux\n",
    "    rng, param_rng, dropout_rng = jax.random.split(rng, 3)\n",
    "    rng_dict = {\"params\": param_rng, 'dropout': dropout_rng}\n",
    "    head_params = head.init(rng_dict, x=input_format, sigma=jnp.ones([1,]), F_x=D_x, last_x_emb=last_x_emb, t_emb=t_emb,\n",
    "                                    train=False, augment_labels=None)['params']\n",
    "\n",
    "    head_tx = jax_utils.create_optimizer(default_config, \"diffusion\")\n",
    "\n",
    "    new_head_state = TrainState.create(\n",
    "        apply_fn=head.apply,\n",
    "        params=head_params,\n",
    "        params_ema=head_params,\n",
    "        tx=head_tx\n",
    "    )\n",
    "    head_state = new_head_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_from_checkpoint_dir(checkpoint_dir, state, step, checkpoint_prefix=\"checkpoint_\"):\n",
    "    state = checkpoints.restore_checkpoint(checkpoint_dir, state, prefix=checkpoint_prefix, step=step)\n",
    "    print(f\"Checkpoint {state.step} loaded\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_state_flax(model_type, state, checkpoint_dir=None):\n",
    "    # prefix = self.get_state_prefix(model_type)\n",
    "    prefix = model_type\n",
    "    prefix = prefix + \"_\" if prefix[-1] != \"_\" else prefix\n",
    "    \n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = default_config.exp.checkpoint_dir\n",
    "    state = jax_utils.load_state_from_checkpoint_dir(checkpoint_dir, state, None, prefix)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing field target_model in state dict while restoring an instance of TrainState, at path .",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# torso_state = load_model_state_flax(torso_prefix, torso_state)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m torso_state \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_state_flax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorso_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorso_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorso_checkpoint_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiffusion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torso_state\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m: \u001b[38;5;66;03m# not default_config.framework.diffusion.only_cm_training:\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mload_model_state_flax\u001b[0;34m(model_type, state, checkpoint_dir)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     checkpoint_dir \u001b[38;5;241m=\u001b[39m default_config\u001b[38;5;241m.\u001b[39mexp\u001b[38;5;241m.\u001b[39mcheckpoint_dir\n\u001b[0;32m----> 8\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mjax_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_from_checkpoint_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "File \u001b[0;32m~/diffusion/utils/jax_utils.py:100\u001b[0m, in \u001b[0;36mload_state_from_checkpoint_dir\u001b[0;34m(checkpoint_dir, state, step, checkpoint_prefix)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_state_from_checkpoint_dir\u001b[39m(checkpoint_dir, state, step, checkpoint_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 100\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(state) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    102\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/training/checkpoints.py:993\u001b[0m, in \u001b[0;36mrestore_checkpoint\u001b[0;34m(ckpt_dir, target, step, prefix, parallel, gda_manager, allow_partial_mpa_restoration, orbax_checkpointer, orbax_transforms)\u001b[0m\n\u001b[1;32m    991\u001b[0m   restored_checkpoint \u001b[38;5;241m=\u001b[39m state_dict\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 993\u001b[0m   restored_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    996\u001b[0m monitoring\u001b[38;5;241m.\u001b[39mrecord_event_duration_secs(_READ_CHECKPOINT_EVENT,\n\u001b[1;32m    997\u001b[0m                                       end_time \u001b[38;5;241m-\u001b[39m start_time)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/serialization.py:92\u001b[0m, in \u001b[0;36mfrom_state_dict\u001b[0;34m(target, state, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m ty_from_state_dict \u001b[38;5;241m=\u001b[39m _STATE_DICT_REGISTRY[ty][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _record_path(name):\n\u001b[0;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mty_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/struct.py:151\u001b[0m, in \u001b[0;36mdataclass.<locals>.from_state_dict\u001b[0;34m(x, state)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m data_fields:\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing field \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in state dict while restoring\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    152\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclz\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    153\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m at path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mserialization\u001b[38;5;241m.\u001b[39mcurrent_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    154\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, name)\n\u001b[1;32m    155\u001b[0m   value_state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(name)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing field target_model in state dict while restoring an instance of TrainState, at path ."
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     fs_utils.load_model_state(states)\n",
    "#     raise ValueError(\"Model state is loaded\")\n",
    "# except:\n",
    "model_dict = {}\n",
    "torso_checkpoint_dir = 'experiments/ict_1024_240109/checkpoints' # diffusion_framework['torso_checkpoint_path']\n",
    "torso_prefix = \"torso\"\n",
    "if torso_checkpoint_dir is not None:\n",
    "    torso_prefix = \"diffusion\"\n",
    "else:\n",
    "    for checkpoint in os.listdir(default_config.exp.checkpoint_dir):\n",
    "        if torso_prefix in checkpoint:\n",
    "            torso_checkpoint_dir = default_config.exp.checkpoint_dir\n",
    "            break\n",
    "# torso_state = load_model_state_flax(torso_prefix, torso_state)\n",
    "torso_state = load_model_state_flax(torso_prefix, torso_state, torso_checkpoint_dir)\n",
    "model_dict['diffusion'] = torso_state\n",
    "\n",
    "if False: # not default_config.framework.diffusion.only_cm_training:\n",
    "    head_checkpoint_dir = diffusion_framework['head_checkpoint_path']\n",
    "    head_prefix = \"head\"\n",
    "    for checkpoint in os.listdir(default_config.exp.checkpoint_dir):\n",
    "        if \"head\" in checkpoint:\n",
    "            head_checkpoint_dir = default_config.exp.checkpoint_dir\n",
    "            break\n",
    "    head_state = load_model_state_flax(head_prefix, head_state)\n",
    "    \n",
    "    model_dict['head'] = head_state\n",
    "\n",
    "# fs_utils.load_model_state(model_dict)\n",
    "step = torso_state.step\n",
    "abs_path_ = os.getcwd() + \"/\"\n",
    "tmp_checkpoint_path = abs_path_ + default_config.exp.checkpoint_dir + \"/\" + \"migration\"\n",
    "\n",
    "options = orbax.checkpoint.CheckpointManagerOptions(create=True)\n",
    "model_checkpoint_manager = orbax.checkpoint.CheckpointManager(\n",
    "    tmp_checkpoint_path,\n",
    "    {model_key: orbax.checkpoint.PyTreeCheckpointer() for model_key in model_dict.keys()})\n",
    "model_checkpoint_manager.save(step, model_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments/1210_CT_joint_training_new_loss_official_unetpp/checkpoints/800010'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "migrated_ckpt = os.listdir(tmp_checkpoint_path)[0]\n",
    "shutil.move(tmp_checkpoint_path + \"/\" + migrated_ckpt, default_config.exp.checkpoint_dir + \"/\" + migrated_ckpt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
