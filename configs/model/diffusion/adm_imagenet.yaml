type: "adm"

image_size: 64
in_channels: 3
model_channels: 192
out_channels: 3
num_res_blocks: 3
attention_resolutions: [32, 16, 8]
dropout: 0.2
channel_mult: [1, 2, 4, 8]
conv_resample: True
dims: 2
num_classes: 1000
use_checkpoint: False
num_heads: 1
num_head_channels: 64
num_heads_upsample: -1
# use_scale_shift_norm: False, # This should embedded in fp16 options
use_scale_shift_norm: True
resblock_updown: True
use_new_attention_order: True