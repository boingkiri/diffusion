defaults:
  # - framework: ldm
  - framework: 
    # - diffusion/ddim
    # - diffusion/ddpm
    # - diffusion/improved_ddpm
    # - diffusion/edm
    - diffusion/cm
    # - diffusion/cm_diffusion
  - model: 
    # - autoencoder/autoencoder_kl
    # - discriminator/discriminator_kl
    # - diffusion/dit_b
    # - diffusion/unet
    # - diffusion/unetpp
    - diffusion/unetpp_cm
  # - ema: ema_edm
  - ema: ema
  - dataset: cifar10
  - exp: exp_setting

# type: ddpm ddim ldm edm (const_dist, const_train: NEW!)
# type: edm
type: cm_diffusion
# type: ${framework.diffusion.type}
exp_name: cm_default_experiment
do_training: true
do_sampling: true
num_sampling: 50000
sampling_batch: 256
rand_seed: 42
fid_during_training: true # True when calculating fid during training, otherwise, false.
n_jitted_steps: 100

available_gpus: "0, 1, 2, 3, 4, 5, 6, 7"

distributed_training: True
PAE_evaluation: True

framework:
  train_idx: 2
  # pretrained_ae: "ldm_vq_cifar10_with_gan"

hydra:  
  output_subdir: null  
  run:  
    dir: .

