framework:
  diffusion:
    type: edm
    beta:
      - 0.0001
      - 0.02
    n_timestep: 18
    loss: l2
    noise_schedule: linear
    learn_sigma: false
    sigma_min: 0.002
    sigma_max: 80
    rho: 7
    deterministic_sampling: true
    S_churn: 30
    S_min: 0.01
    S_max: 1
    S_noise: 1.007
    train:
      learning_rate: 0.001
      warmup: 19532
      batch_size: 512
      total_step: 400000
      sampling_step: 10000
      saving_step: 100000
      optimizer:
        type: Adam
train_idx: 2
model:
  diffusion:
    type: unetpp
    image_channels: 3
    n_channels: 128
    label_dim: 0
    augment_dim: 9
    ch_mults:
      - 2
      - 2
      - 2
    is_atten:
      - false
      - true
      - false
    n_blocks: 4
    n_heads: 1
    n_groups: 32
    dropout_rate: 0.13
    label_dropout_rate: 0.0
    embedding_type: fourier
    encoder_type: residual
    decoder_type: standard
    resample_filter:
      - 1
      - 3
      - 3
      - 1
    learn_sigma: false
ema:
  beta: 0.5
  update_every: 1
  update_after_step: 0
  ema_rampup_ratio: 0.05
  ema_halflife_number: 500000
dataset:
  name: cifar10
  data_size:
    - 32
    - 32
    - 3
exp:
  exp_dir: experiments
  current_exp_dir: experiments/edm_porting_from_torch_ve
  sampling_dir: experiments/edm_porting_from_torch_ve/sampling
  in_process_dir: experiments/edm_porting_from_torch_ve/in_process
  checkpoint_dir: experiments/edm_porting_from_torch_ve/checkpoints
  best_dir: experiments/edm_porting_from_torch_ve/checkpoints/best
  autoencoder_prefix: ae_
  discriminator_prefix: discriminator_
  diffusion_prefix: diffusion_
  # type: ${framework.diffusion.type}
  exp_name: edm_porting_from_torch_ve
do_training: false
do_sampling: true
num_sampling: 50000
sampling_batch: 256
rand_seed: 42
fid_during_training: true
n_jitted_steps: 10
