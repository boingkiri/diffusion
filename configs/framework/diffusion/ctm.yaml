type: "ctm"
beta: [0.0001, 0.02]
n_timestep: 18
loss: "lpips"

sigma_min: 0.002
sigma_max: 80
rho: 7

use_pretrained_score_model: True
pretrained_score_type: "edm"
pretrained_score_path: /home/djfelrl11/diffusion/experiments/edm_porting_from_torch_ve/checkpoints

deterministic_sampling: True
S_churn: 30
S_min: 0.01
S_max: 1
S_noise: 1.007
params_ema_for_training: [0.9, 2, 150] # mu_0, s_0, s_1
target_model_ema_decay: 0.999

dsm_weight: 

train:
  learning_rate: 2.0e-4
  gradient_clip: 1.0
  warmup: 5000
  batch_size: 256
  total_step: 100000
  sampling_step: 10000
  saving_step: 100000
  optimizer:
    type: "Adam"
